<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Deep Learning in a nutshell - a tour de force</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js/css/reveal.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
tex2jax: {
  inlineMath: [["\\(", "\\)"]],
  displayMath: [["\\[", "\\]"]],
  ignoreClass: "nostem|nolatexmath"
},
asciimath2jax: {
  delimiters: [["\\$", "\\$"]],
  ignoreClass: "nostem|noasciimath"
},
TeX: { equationNumbers: { autoNumber: "none" } }
});</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.4.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script><link href="reveal.js/lib/css/zenburn.css" rel="stylesheet"><script>var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? "reveal.js/css/print/pdf.css" : "reveal.js/css/print/paper.css";
document.getElementsByTagName( 'head' )[0].appendChild( link );</script><!--[if lt IE 9]><script src="reveal.js/lib/js/html5shiv.js"></script><![endif]--><link rel="stylesheet" href="custom.css"></head><body><div class="reveal"><div class="slides"><section class="title" data-state="title"><h1>Deep Learning in a nutshell - a tour de force</h1><div class="preamble"><div class="paragraph"><p><a href="https://tu-dresden.de/mn/physik/iktp/das-institut/termine/termine/peter-steinbac-machine-learning">IKTP Institute Seminar</a><br></p></div>
<div class="paragraph"><p><a href="mailto:steinbach@scionics.de">Peter Steinbach</a>, October 11, 2018, Dresden, Germany</p></div></div></section>
<section><section id="preface"><h2>Preface</h2></section><section id="my_employer"><h2>My employer</h2><div class="imageblock" style=""><img src="images/scionics_main_logo.png" alt="scionics main logo" width="80%"></div>
<div class="paragraph"><p><a href="https://scionics.de">Scionics Computer Innovation GmbH</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>offer scientific consulting</p></li><li><p>data analysis, large data handling, &#8230;&#8203;</p></li></ul></div></aside></section><section id="our_client_mpi_cbg"><h2>Our client: <a href="https://mpi-cbg.de">MPI CBG</a></h2><div class="imageblock" style=""><img src="images/x600px-MPI-CBG_building_outside_4pl.jpg" alt="x600px MPI CBG building outside 4pl"></div>
<div class="paragraph"><p><a href="https://mpi-cbg.de">Max Planck Institute for Molecular Cell Biology and Genetics</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>scientific computing facility</p></li><li><p>my role</p></li></ul></div></aside></section><section id="disclaimer"><h2>Disclaimer</h2><div class="imageblock stretch" style=""><img src="images/bart_simpson_white.png" alt="bart simpson white" height="100%"></div>
<div class="paragraph"><p>These slides are open-source:</p></div>
<div class="paragraph"><p><a href="https://github.com/psteinb/deeplearning-at-iktp2018">github.com/psteinb/deeplearning-at-iktp2018</a></p></div></section></section>
<section><section id="a_detour_trackml"><h2>A Detour: <a href="https://indico.cern.ch/event/587955/contributions/2937510/attachments/1683248/2705359/20180712-msmk-trackml-v3.pdf">TrackML</a></h2><div class="imageblock" style=""><img src="images/chep2018-mkiehn-p3.png" alt="chep2018 mkiehn p3"></div><aside class="notes"><div class="ulist"><ul><li><p>Are there better approaches?</p></li><li><p>How to find them?</p></li><li><p>Do we have to do it ourselves?</p></li><li><p>Use challenge format to look for new solutions</p></li></ul></div></aside></section><section id="trackml_flow"><h2><a href="https://indico.cern.ch/event/587955/contributions/2937510/attachments/1683248/2705359/20180712-msmk-trackml-v3.pdf">TrackML flow</a></h2><div class="imageblock" style=""><img src="images/chep2018-mkiehn-p4.png" alt="chep2018 mkiehn p4"></div></section><section id="trackml_challenge"><h2><a href="https://indico.cern.ch/event/587955/contributions/2937510/attachments/1683248/2705359/20180712-msmk-trackml-v3.pdf">TrackML Challenge</a></h2><div class="imageblock" style=""><img src="images/chep2018-mkiehn-p5.png" alt="chep2018 mkiehn p5"></div></section><section id="trackml_status"><h2><a href="https://indico.cern.ch/event/587955/contributions/2937510/attachments/1683248/2705359/20180712-msmk-trackml-v3.pdf">TrackML status</a></h2><div class="imageblock" style=""><img src="images/chep2018-mkiehn-p7.png" alt="chep2018 mkiehn p7"></div></section><section id="trackml_results" data-background-image="images/trackml-accuracy-phase-leaderboard.png" data-background-size="cover"><h2><a href="https://indico.cern.ch/event/587955/contributions/2937510/attachments/1683248/2705359/20180712-msmk-trackml-v3.pdf">TrackML results</a></h2></section><section id="which_approach_won" data-background-image="images/pexels-bright-bulb-dark-132340_1024px.jpg" data-background-size="cover"><h2>Which approach won?</h2>
<aside class="notes"><div class="ulist"><ul><li><p>Wait until the end!</p></li></ul></div></aside></section><section id="the_no_free_lunch_theorem"><h2>The No Free Lunch Theorem</h2><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa fa-info-circle" title="Note"></i></td><td class="content"><div class="title">By <a href="http://www.no-free-lunch.org/">David Wolpert</a></div><div class="paragraph"><p>Averaged over all possible data generating distributions, every classification algorithm has the same error
rate when classifying previously unobserved points.</p></div></td></tr></table></div>
<aside class="notes"><div class="ulist"><ul><li><p>Ian Goodfellow: No machine learning algorithm is universally any better than any other.</p></li><li><p>Extra: The most sophisticated algorithm we can conceive of has the same average performance (over
all possible tasks) as merely predicting that every point belongs to the same class.</p></li></ul></div></aside></section><section id="what" data-background-image="images/pexels-photo-sad.jpg" data-background-size="cover"><h2>What?</h2></section><section id="machine_learning_means"><h2>Machine Learning means</h2><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa fa-info-circle" title="Note"></i></td><td class="content"><div class="title">By <a href="https://www.deeplearningbook.org/">Ian Goodfellow</a></div><div class="paragraph"><p>This means that the goal of machine learning research is not to seek a universal learning algorithm or the absolute best learning algorithm. Instead, <strong>our goal is to understand what kinds of distributions are relevant to the “real world”</strong> that an AI agent experiences, and what kinds of machine learning algorithms perform well on data drawn from the kinds of data generating distributions we care about.</p></div></td></tr></table></div>
<aside class="notes"><div class="ulist"><ul><li><p>Show you yet another technique: Deep Learning!</p></li></ul></div></aside></section></section>
<section><section id="deep_learning"><h2>Deep Learning</h2><div class="ulist"><ul><li class="fragment"><p>branch of machine learning</p></li><li class="fragment"><p>learning data representations</p></li><li class="fragment"><p>supervised, semi-supervised or unsupervised learning</p></li><li class="fragment"><p>applications in many fields</p></li></ul></div></section><section id="object_detection"><h2>Object Detection</h2><div class="videoblock stretch"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/VOC3huqHrss?rel=0&amp;start=5" frameborder="0" allowfullscreen></iframe></div></section><section id="image_alteration"><h2>Image Alteration</h2><div class="imageblock" style=""><img src="images/horse2zebra.gif" alt="horse2zebra" width="100%"></div>
<div class="paragraph"><p>by <a href="https://github.com/junyanz/CycleGAN" class="bare">https://github.com/junyanz/CycleGAN</a></p></div></section><section id="image_restoration"><h2>Image Restoration</h2><table class="tableblock frame-none grid-none" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><tbody><tr><td class="tableblock halign-center valign-top"><div><div class="paragraph"><p><span class="image"><img src="images/denoising_planaria_magma_input.png" alt="denoising planaria magma input" width="100%"></span></p></div></div></td><td class="tableblock halign-center valign-top"><div><div class="paragraph"><p><span class="image"><img src="images/denoising_planaria_magma_network.png" alt="denoising planaria magma network" width="100%"></span></p></div></div></td></tr><tr><td class="tableblock halign-center valign-top"><p class="tableblock"><strong>Planaria Worm from Microscope</strong></p></td><td class="tableblock halign-center valign-top"><p class="tableblock"><strong>Planaria Worm after DL</strong></p></td></tr></table></section><section id="relying_on_weights_can_be_dangerous"><h2>Relying on Weights can be dangerous</h2><div class="imageblock" style=""><img src="images/putin-on-horse.jpg" alt="putin on horse" width="100%"></div>
<div class="paragraph"><p>from <a href="https://twitter.com/genekogan/status/855032573327581185" class="bare">https://twitter.com/genekogan/status/855032573327581185</a></p></div></section></section></div></div><script src="reveal.js/lib/js/head.min.js"></script><script src="reveal.js/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: true,
  // Display a presentation progress bar
  progress: true,
  // Set a per-slide timing for speaker notes, null means none
  defaultTiming: null,
  // Display the page number of the current slide
  slideNumber: true,
  // Push each slide change to the browser history
  history: false,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: false,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Randomizes the order of slides each time the presentation loads
  shuffle: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Flags if we should show a help overlay when the questionmark
  // key is pressed
  help: true,
  // Flags if speaker notes should be visible to all viewers
  showNotes: false,
  // Global override for autolaying embedded media (video/audio/iframe)
  // - null: Media will only autoplay if data-autoplay is present
  // - true: All media will autoplay, regardless of individual setting
  // - false: No media will autoplay, regardless of individual setting
  autoPlayMedia: null,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'black',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'slide',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'reveal.js/plugin/notes/notes.js', async: true }
  ]
});</script></body></html>